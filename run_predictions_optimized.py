#!/usr/bin/env python3
"""
NBA Predictions - Script Principal Optimis√© (NBA-22 v2.0)
Pipeline complet avec calibration, feature selection et monitoring

Usage:
    python run_predictions_optimized.py              # Pr√©dictions avec mod√®le optimis√©
    python run_predictions_optimized --update        # Mise √† jour r√©sultats
    python run_predictions_optimized --report        # Rapport performance
    python run_predictions_optimized --train         # R√©entra√Æner le mod√®le
    python run_predictions_optimized --health        # Check sant√© syst√®me
    python run_predictions_optimized --drift         # V√©rifier data drift

Configuration via fichier .env (voir .env.example)
"""

import argparse
import sys
import json
from pathlib import Path
from datetime import datetime

# Ajouter src au path
sys.path.insert(0, str(Path(__file__).parent / 'src' / 'ml' / 'pipeline'))
sys.path.insert(0, str(Path(__file__).parent))

import pandas as pd
import numpy as np
import joblib
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Configuration centralis√©e
from nba.config import settings

from daily_pipeline import DailyPredictionPipeline
from tracking_roi import ROITracker
from nba_live_api import get_today_games
from probability_calibration import ProbabilityCalibrator
from drift_monitoring import DataDriftMonitor, check_system_health


class OptimizedPredictionPipeline:
    """
    Pipeline de pr√©diction optimis√© avec calibration et s√©lection de features.
    """
    
    def __init__(self, use_optimized=True):
        self.use_optimized = use_optimized
        self.model = None
        self.calibrator = None
        self.selected_features = None
        self.historical_data = None
        self.team_name_to_id = None
        
    def load_resources(self):
        """Charge les ressources optimis√©es."""
        logger.info("Chargement des ressources...")
        
        # Utilisation de la configuration centralis√©e
        logger.info(f"üìÅ Model path: {settings.model_optimized_path}")
        logger.info(f"üìÅ Predictions path: {settings.predictions_path}")
        logger.info(f"üìÅ Features path: {settings.features_v3_path}")
        
        # Charger la s√©lection de features
        if settings.selected_features_path.exists() and self.use_optimized:
            with open(settings.selected_features_path) as f:
                features_data = json.load(f)
                self.selected_features = features_data.get('features', features_data)
            logger.info(f"‚úÖ {len(self.selected_features)} features s√©lectionn√©es charg√©es")
        else:
            self.selected_features = None
            logger.info("‚ÑπÔ∏è Utilisation de toutes les features")
        
        # Charger le mod√®le optimis√©
        if settings.model_xgb_path.exists() and self.use_optimized:
            self.model = joblib.load(settings.model_xgb_path)
            logger.info(f"‚úÖ Mod√®le optimis√© charg√©: {settings.model_xgb_path}")
            
            # Charger le calibrateur
            if settings.calibrator_xgb_path.exists():
                self.calibrator = ProbabilityCalibrator()
                self.calibrator.load(settings.calibrator_xgb_path)
                logger.info("‚úÖ Calibrateur charg√©")
        else:
            # Fallback sur mod√®le V3
            legacy_model = Path("models/week1/xgb_v3.pkl")
            logger.info(f"‚ÑπÔ∏è Mod√®le optimis√© non trouv√©, utilisation du mod√®le V3: {legacy_model}")
            self.model = joblib.load(legacy_model)
            self.selected_features = None
        
        # Charger donn√©es historiques
        self.historical_data = pd.read_parquet(settings.features_v3_path)
        logger.info(f"‚úÖ Donn√©es historiques charg√©es: {settings.features_v3_path}")
        
        # Mapping √©quipes
        if settings.team_mapping_path.exists():
            with open(settings.team_mapping_path) as f:
                self.team_name_to_id = json.load(f)
        else:
            # Fallback
            with open('data/team_name_to_id.json') as f:
                self.team_name_to_id = json.load(f)
        
        # Mapping √©tendu
        team_mapping_extended_path = settings.data_root / "team_mapping_extended.json"
        if team_mapping_extended_path.exists():
            with open(team_mapping_extended_path) as f:
                self.team_mapping_extended = json.load(f)
        else:
            self.team_mapping_extended = {}
            
        logger.info("‚úÖ Mapping √©quipes charg√©")
        
    def get_team_historical_features(self, team_name, is_home=True):
        """R√©cup√®re les derni√®res features d'une √©quipe."""
        team_id = self.team_name_to_id.get(team_name)
        if not team_id:
            logger.warning(f"√âquipe {team_name} non trouv√©e")
            return None
        
        team_id_int = int(team_id)
        
        if is_home:
            matches = self.historical_data[self.historical_data['home_team_id'] == team_id_int]
        else:
            matches = self.historical_data[self.historical_data['away_team_id'] == team_id_int]
        
        if len(matches) == 0:
            return None
        
        return matches.sort_values('game_date').iloc[-1]
    
    def engineer_features_for_match(self, home_team, away_team):
        """Cr√©e les features pour un match."""
        home_hist = self.get_team_historical_features(home_team, is_home=True)
        away_hist = self.get_team_historical_features(away_team, is_home=False)
        
        if home_hist is None or away_hist is None:
            return None
        
        # D√©finir les colonnes features
        exclude_cols = [
            'game_id', 'season', 'game_date', 'season_type',
            'home_team_id', 'away_team_id', 'target',
            'home_score', 'away_score', 'point_diff',
            'home_reb', 'home_ast', 'home_stl', 'home_blk', 'home_tov', 'home_pf',
            'away_reb', 'away_ast', 'away_stl', 'away_blk', 'away_tov', 'away_pf',
            'home_ts_pct', 'home_efg_pct', 'home_game_score', 'home_fatigue_eff',
            'away_ts_pct', 'away_efg_pct', 'away_game_score', 'away_fatigue_eff',
            'ts_pct_diff'
        ]
        
        if self.selected_features:
            feature_cols = self.selected_features
        else:
            feature_cols = [c for c in self.historical_data.columns if c not in exclude_cols]
        
        # Combiner les features
        match_features = {}
        for col in feature_cols:
            if col.startswith('home_'):
                match_features[col] = home_hist.get(col, 0)
            elif col.startswith('away_'):
                match_features[col] = away_hist.get(col, 0)
            else:
                match_features[col] = home_hist.get(col, 0)
        
        return pd.DataFrame([match_features])
    
    def predict_match(self, home_team, away_team):
        """Pr√©dit un match avec calibration."""
        features = self.engineer_features_for_match(home_team, away_team)
        
        if features is None:
            return {
                'home_team': home_team,
                'away_team': away_team,
                'error': 'Donn√©es historiques insuffisantes'
            }
        
        # Pr√©diction
        proba = self.model.predict_proba(features)[0, 1]
        prediction = 1 if proba > 0.5 else 0
        confidence = max(proba, 1 - proba)
        
        # Calibration si disponible
        proba_calibrated = None
        confidence_calibrated = None
        recommendation_calibrated = None
        
        if self.calibrator:
            proba_calibrated = self.calibrator.predict(np.array([proba]))[0]
            confidence_calibrated = max(proba_calibrated, 1 - proba_calibrated)
            recommendation_calibrated = self._get_recommendation(confidence_calibrated)
        
        result = {
            'home_team': home_team,
            'away_team': away_team,
            'prediction': 'Home Win' if prediction == 1 else 'Away Win',
            'proba_home_win': float(proba),
            'confidence': float(confidence),
            'recommendation': self._get_recommendation(confidence),
        }
        
        # Ajouter les valeurs calibr√©es si disponibles
        if proba_calibrated is not None:
            result['proba_home_win_calibrated'] = float(proba_calibrated)
            result['confidence_calibrated'] = float(confidence_calibrated)
            result['recommendation_calibrated'] = recommendation_calibrated
            # Utiliser les valeurs calibr√©es comme principales
            result['confidence'] = float(confidence_calibrated)
            result['recommendation'] = recommendation_calibrated
        
        return result
    
    def _get_recommendation(self, confidence):
        """Recommandation bas√©e sur la confiance."""
        if confidence >= 0.70:
            return "HIGH_CONFIDENCE"
        elif confidence >= 0.60:
            return "MEDIUM_CONFIDENCE"
        elif confidence >= 0.55:
            return "LOW_CONFIDENCE"
        else:
            return "SKIP"
    
    def run_predictions(self):
        """Ex√©cute les pr√©dictions pour tous les matchs du jour."""
        logger.info("\n" + "="*70)
        logger.info("NBA PREDICTIONS OPTIMIS√âES - V2.0")
        logger.info("="*70)
        
        self.load_resources()
        
        # R√©cup√©rer matchs du jour
        games = get_today_games()
        
        if not games:
            logger.info("Aucun match aujourd'hui ou erreur API")
            logger.info("Utilisation des exemples de d√©monstration...")
            games = [
                {'home_team': 'Boston Celtics', 'away_team': 'Los Angeles Lakers'},
                {'home_team': 'Golden State Warriors', 'away_team': 'Phoenix Suns'},
                {'home_team': 'Milwaukee Bucks', 'away_team': 'Miami Heat'}
            ]
        
        # Pr√©dictions
        predictions = []
        for game in games:
            logger.info(f"\nPr√©diction: {game['home_team']} vs {game['away_team']}")
            pred = self.predict_match(game['home_team'], game['away_team'])
            predictions.append(pred)
            
            if 'error' not in pred:
                logger.info(f"  ‚Üí {pred['prediction']}")
                if 'confidence_calibrated' in pred:
                    logger.info(f"  Confiance (calibr√©e): {pred['confidence_calibrated']:.2%}")
                else:
                    logger.info(f"  Confiance: {pred['confidence']:.2%}")
                logger.info(f"  Recommandation: {pred['recommendation']}")
            else:
                logger.warning(f"  ‚Üí ERREUR: {pred['error']}")
        
        # Sauvegarder
        self._save_predictions(predictions)
        
        # Tracking ROI
        tracker = ROITracker()
        for pred in predictions:
            if 'error' not in pred:
                tracker.add_prediction(pred)
        tracker.save()
        
        # R√©sum√©
        self._print_summary(predictions)
        
        return predictions
    
    def _save_predictions(self, predictions):
        """Sauvegarde les pr√©dictions."""
        output_dir = Path('predictions')
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # CSV
        df = pd.DataFrame(predictions)
        df.to_csv(output_dir / f"predictions_optimized_{timestamp}.csv", index=False)
        df.to_csv(output_dir / "latest_predictions_optimized.csv", index=False)
        
        # JSON
        with open(output_dir / f"predictions_optimized_{timestamp}.json", 'w') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'model': 'optimized_xgb',
                'predictions': predictions
            }, f, indent=2)
        
        logger.info(f"\n‚úÖ Pr√©dictions sauvegard√©es dans {settings.predictions_path}/")
    
    def _print_summary(self, predictions):
        """Affiche le r√©sum√©."""
        valid_preds = [p for p in predictions if 'error' not in p]
        
        if not valid_preds:
            return
        
        print("\n" + "="*70)
        print("R√âSUM√â DES PR√âDICTIONS")
        print("="*70)
        
        high_conf = sum(1 for p in valid_preds if p['recommendation'] == 'HIGH_CONFIDENCE')
        med_conf = sum(1 for p in valid_preds if p['recommendation'] == 'MEDIUM_CONFIDENCE')
        low_conf = sum(1 for p in valid_preds if p['recommendation'] == 'LOW_CONFIDENCE')
        skip = sum(1 for p in valid_preds if p['recommendation'] == 'SKIP')
        
        print(f"\nTotal matchs:       {len(valid_preds)}")
        print(f"Haute confiance:    {high_conf}")
        print(f"Moyenne confiance:  {med_conf}")
        print(f"Basse confiance:    {low_conf}")
        print(f"Ignorer:            {skip}")
        
        if self.calibrator:
            print("\n[OK] Probabilit√©s calibr√©es activ√©es")
        if self.selected_features:
            print(f"[OK] Feature selection: {len(self.selected_features)} features")
        
        print("="*70)


def update_results():
    """Met √† jour les r√©sultats des matchs."""
    print("="*70)
    print("MISE √Ä JOUR DES R√âSULTATS")
    print("="*70)
    
    tracker = ROITracker()
    
    # Charger pr√©dictions optimis√©es ou normales
    latest_file = settings.latest_predictions_path
    if not latest_file.exists():
        latest_file = settings.predictions_path / 'latest_predictions.csv'
    
    if not latest_file.exists():
        print("[ERREUR] Aucune pr√©diction trouv√©e")
        return
    
    predictions = pd.read_csv(latest_file)
    
    print(f"\nPr√©dictions √† mettre √† jour: {len(predictions)}")
    
    for idx, row in predictions.iterrows():
        home = row['home_team']
        away = row['away_team']
        date = datetime.now().strftime('%Y-%m-%d')
        
        print(f"\n{idx+1}. {home} vs {away}")
        
        result = input("R√©sultat (h=Home Win, a=Away Win, s=Skip): ").lower().strip()
        
        if result == 'h':
            tracker.update_result(home, away, date, 'HOME_WIN')
        elif result == 'a':
            tracker.update_result(home, away, date, 'AWAY_WIN')
        elif result == 's':
            print("  [SKIP]")
    
    tracker.save()
    print("\n‚úÖ Mise √† jour termin√©e")


def generate_report():
    """G√©n√®re le rapport de performance."""
    tracker = ROITracker()
    tracker.export_results()


def train_model():
    """Lance l'entra√Ænement optimis√©."""
    logger.info("Lancement de l'entra√Ænement optimis√©...")
    
    from train_optimized import OptimizedNBA22Trainer
    
    trainer = OptimizedNBA22Trainer()
    results = trainer.run()
    
    return results


def check_health():
    """V√©rifie la sant√© du syst√®me."""
    health = check_system_health(
        features_path="data/gold/ml_features/features_v3.parquet",
        predictions_dir="predictions",
        reference_path="data/gold/ml_features/features_v3.parquet"
    )
    
    # Sauvegarder le rapport
    with open(settings.predictions_path / 'health_report.json', 'w') as f:
        json.dump(health, f, indent=2)
    
    return health


def check_drift():
    """V√©rifie le data drift."""
    logger.info("V√©rification du data drift...")
    
    monitor = DataDriftMonitor(
        reference_data_path="data/gold/ml_features/features_v3.parquet",
        alert_threshold=0.05
    )
    
    # Charger donn√©es r√©centes (30 derniers matchs)
    current_data = pd.read_parquet("data/gold/ml_features/features_v3.parquet").tail(30)
    
    # S√©lectionner quelques features importantes
    important_features = [
        'home_win_pct', 'away_win_pct', 'win_pct_diff',
        'home_avg_pts_last_5', 'away_avg_pts_last_5'
    ]
    
    drift_result = monitor.detect_feature_drift(current_data, important_features)
    
    # Sauvegarder le rapport
    monitor.save_report(settings.predictions_path / 'drift_report.json')
    
    return drift_result


def main():
    parser = argparse.ArgumentParser(description='NBA Predictions Optimized v2.0')
    parser.add_argument('--update', action='store_true',
                       help='Mettre √† jour les r√©sultats des matchs')
    parser.add_argument('--report', action='store_true',
                       help='G√©n√©rer le rapport de performance')
    parser.add_argument('--train', action='store_true',
                       help='R√©entra√Æner le mod√®le optimis√©')
    parser.add_argument('--health', action='store_true',
                       help='V√©rifier la sant√© du syst√®me')
    parser.add_argument('--drift', action='store_true',
                       help='V√©rifier le data drift')
    parser.add_argument('--legacy', action='store_true',
                       help='Utiliser le mod√®le V3 (non optimis√©)')
    
    args = parser.parse_args()
    
    if args.update:
        update_results()
    elif args.report:
        generate_report()
    elif args.train:
        train_model()
    elif args.health:
        check_health()
    elif args.drift:
        check_drift()
    else:
        # Mode par d√©faut: pr√©dictions
        use_optimized = not args.legacy
        pipeline = OptimizedPredictionPipeline(use_optimized=use_optimized)
        pipeline.run_predictions()


if __name__ == '__main__':
    main()
