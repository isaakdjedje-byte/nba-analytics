# ðŸ“‹ Commandes de DÃ©monstration - NBA Analytics Platform
## Copier-coller prÃªt Ã  l'emploi

---

## ðŸš€ DÃ‰MARRAGE RAPIDE (30 secondes)

```bash
# VÃ©rifier version
nba version

# Voir le catalogue
nba catalog list

# Exporter un dataset
nba export team_season_stats --format csv
```

---

## âœ… PHASE 1 : VALIDATION (2 minutes)

```bash
# ExÃ©cuter tous les tests (82 tests)
./run_all_tests.sh --docker --e2e

# VÃ©rifier que tout passe
echo "Tests terminÃ©s avec succÃ¨s !"
```

**Sortie attendue :** âœ… 82 tests passed

---

## ðŸ§  PHASE 2 : MACHINE LEARNING (8 minutes)

### 2.1 MÃ©triques du ModÃ¨le
```bash
# Afficher les mÃ©triques complÃ¨tes
cat models/optimized/training_summary.json | python -m json.tool

# Afficher les 10 features les plus importantes
python -c "
import json
with open('models/optimized/selected_features.json') as f:
    features = json.load(f)
    print('Top 10 features :')
    for i, f in enumerate(features[:10], 1):
        print(f'{i:2d}. {f}')
    print(f'\nTotal : {len(features)} features sÃ©lectionnÃ©es')
"
```

**MÃ©triques clÃ©s Ã  souligner :**
- **Accuracy : 76.65%**
- **AUC : 84.9%**
- **Features : 35** (sÃ©lectionnÃ©es parmi 85)
- **Brier Score : 0.158** (probabilitÃ©s bien calibrÃ©es)

### 2.2 GÃ©nÃ©rer PrÃ©dictions
```bash
# GÃ©nÃ©rer prÃ©dictions du jour avec l'API NBA Live
python run_predictions_optimized.py

# VÃ©rifier les rÃ©sultats formatÃ©s
cat predictions/latest_predictions_optimized.csv | column -t -s,

# Compter les recommandations HIGH_CONFIDENCE
grep -c "HIGH_CONFIDENCE" predictions/latest_predictions_optimized.csv

# Afficher uniquement les HIGH_CONFIDENCE
grep "HIGH_CONFIDENCE" predictions/latest_predictions_optimized.csv | column -t -s,
```

### 2.3 VÃ©rifications SystÃ¨me
```bash
# VÃ©rifier santÃ© du systÃ¨me
python run_predictions_optimized.py --health

# VÃ©rifier si donnÃ©es ont driftÃ©
python run_predictions_optimized.py --drift

# Voir le rapport de performance
python run_predictions_optimized.py --report
```

---

## ðŸ³ PHASE 3 : INFRASTRUCTURE (5 minutes)

### Docker & Services
```bash
# VÃ©rifier l'Ã©tat des services Docker
docker-compose ps

# DÃ©marrer les services (si nÃ©cessaire)
docker-compose up -d postgres redis api

# VÃ©rifier logs d'un service
docker-compose logs --tail=50 api
```

### API REST
```bash
# Test health endpoint
curl http://localhost:8000/health

# Lister tous les datasets via API
curl http://localhost:8000/api/v1/datasets | python -m json.tool

# Obtenir dÃ©tails d'un dataset
curl http://localhost:8000/api/v1/datasets/team_season_stats | python -m json.tool

# Exporter via API
curl -X POST http://localhost:8000/api/v1/export \
  -H "Content-Type: application/json" \
  -d '{"dataset": "team_season_stats", "format": "csv"}'

# Scanner le catalogue via API
curl -X POST http://localhost:8000/api/v1/catalog/scan
```

### Lancer l'API en local
```bash
# MÃ©thode 1 : Via CLI
nba dev api

# MÃ©thode 2 : Via Python
python -m nba.api.main

# Avec rechargement auto (dÃ©veloppement)
nba dev api --reload

# Sur port diffÃ©rent
nba dev api --port 8080
```

---

## ðŸ’° PHASE 4 : ROI & BUSINESS (3 minutes)

### Tracking & Performance
```bash
# GÃ©nÃ©rer rapport de performance complet
python run_predictions_optimized.py --report

# Afficher rapport
 cat predictions/performance_report.txt

# Voir l'historique complet des prÃ©dictions
cat predictions/tracking_history.csv | column -t -s,

# Nombre total de prÃ©dictions trackÃ©es
wc -l predictions/tracking_history.csv

# DerniÃ¨res prÃ©dictions avec rÃ©sultats
tail -10 predictions/tracking_history.csv | column -t -s,
```

### Analyse Performance
```bash
# Calculer accuracy globale
python -c "
import pandas as pd
df = pd.read_csv('predictions/tracking_history.csv')
accuracy = df['correct'].mean() * 100
print(f'Accuracy globale : {accuracy:.1f}%')
print(f'Nombre de prÃ©dictions : {len(df)}')
"

# Performance par niveau de confiance
python -c "
import pandas as pd
df = pd.read_csv('predictions/tracking_history.csv')
for conf in ['HIGH_CONFIDENCE', 'MEDIUM_CONFIDENCE', 'LOW_CONFIDENCE']:
    subset = df[df['recommendation'] == conf]
    if len(subset) > 0:
        acc = subset['correct'].mean() * 100
        print(f'{conf}: {acc:.1f}% ({len(subset)} prÃ©dictions)')
"
```

---

## ðŸŽ¬ PHASE 5 : INTERACTIVE (2 minutes)

### Export Multi-Formats
```bash
# CrÃ©er rÃ©pertoire de dÃ©mo
mkdir -p demo_exports

# Export CSV (Excel-friendly)
nba export team_season_stats --format csv --output demo_exports

# Export Parquet (analytics)
nba export team_season_stats --format parquet --output demo_exports

# Export JSON (API)
nba export team_season_stats --format json --output demo_exports

# VÃ©rifier exports
ls -lh demo_exports/

# Tous les datasets d'un coup
nba export all --output demo_exports --format csv
```

### CLI - Catalogue
```bash
# Lister datasets
nba catalog list

# Scanner et mettre Ã  jour le catalogue
nba catalog scan

# Voir dÃ©tails d'un dataset
nba catalog show --dataset team_season_stats

# Export catalogue complet
nba export all --format json --output ./catalog_export
```

### Exploration DonnÃ©es
```bash
# Nombre de datasets gold
ls data/gold/*/*.parquet | wc -l

# Taille totale des donnÃ©es
du -sh data/

# Derniers fichiers modifiÃ©s
ls -lt data/gold/*/* | head -10

# Statistiques rapides
python -c "
import pandas as pd
df = pd.read_parquet('data/gold/team_season_stats/team_season_stats.parquet')
print(f'Nombre Ã©quipes : {len(df)}')
print(f'Colonnes : {len(df.columns)}')
print(f'Taille : {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB')
"
```

---

## ðŸŽ¯ COMMANDES SPÃ‰CIALES

### Mode Paper Trading
```bash
# PrÃ©dictions quotidiennes automatiques
python run_predictions_optimized.py

# Mise Ã  jour des rÃ©sultats (aprÃ¨s les matchs)
python run_predictions_optimized.py --update

# Rapport hebdomadaire
python run_predictions_optimized.py --report

# Voir historique complet
cat predictions/tracking_history.csv
```

### RÃ©entraÃ®nement ModÃ¨le
```bash
# RÃ©entraÃ®ner avec nouvelles donnÃ©es
python src/ml/pipeline/train_optimized.py

# VÃ©rifier nouvelles mÃ©triques
cat models/optimized/training_summary.json | python -m json.tool

# Comparer avec ancien modÃ¨le
ls -lt models/optimized/
```

### Tests SpÃ©cifiques
```bash
# Tests ML critiques
pytest tests/test_ml_pipeline_critical.py -v

# Tests E2E
pytest tests/e2e/test_pipeline.py -v

# Tests avec couverture
pytest tests/ --cov=nba --cov-report=html
```

---

## ðŸ› ï¸ DÃ‰PANNAGE

### Si les tests Ã©chouent
```bash
# Nettoyer et relancer
docker-compose down
docker-compose up -d postgres redis
./run_all_tests.sh

# Voir logs dÃ©taillÃ©s
./run_all_tests.sh --docker --e2e 2>&1 | tee test_output.log
```

### Si l'API ne rÃ©pond pas
```bash
# VÃ©rifier port utilisÃ©
netstat -an | grep 8000  # Windows
lsof -i :8000            # Mac/Linux

# Relancer sur port diffÃ©rent
nba dev api --port 8001

# VÃ©rifier processus Python
ps aux | grep python  # Mac/Linux
tasklist | findstr python  # Windows
```

### Si erreur Unicode (Windows)
```bash
# Changer page de code
chcp 65001

# Ou utiliser Windows Terminal
# Ou dÃ©finir variable d'environnement
set PYTHONIOENCODING=utf-8
```

### ProblÃ¨mes Docker
```bash
# Nettoyer conteneurs orphelins
docker-compose down --remove-orphans

# Reconstruire images
docker-compose up -d --build

# VÃ©rifier espace disque
docker system df

# Nettoyer si nÃ©cessaire
docker system prune -f
```

### Reset Complet
```bash
# Supprimer donnÃ©es et recommencer
rm -rf data/exports/*
rm -rf predictions/*.csv
rm -rf models/optimized/*
docker-compose down
./run_all_tests.sh --docker --e2e
```

---

## ðŸ“Š STATISTIQUES RAPIDES

```bash
# Nombre total de matchs analysÃ©s
python -c "
import pandas as pd
df = pd.read_parquet('data/gold/ml_features/features_all.parquet')
print(f'Matchs analysÃ©s : {len(df):,}')
"

# Nombre de joueurs
python -c "
import pandas as pd
df = pd.read_parquet('data/gold/player_team_season/player_team_season.parquet')
print(f'Joueurs : {len(df):,}')
"

# PÃ©riode couverte
python -c "
import pandas as pd
df = pd.read_parquet('data/gold/team_season_stats/team_season_stats.parquet')
print(f'Saisons : {df[\"season\"].nunique()}')
print(f'AnnÃ©es : {sorted(df[\"season\"].unique())}')
"

# DerniÃ¨re mise Ã  jour
stat predictions/latest_predictions_optimized.csv

# Taille du catalogue
ls -lh data/catalog.db
```

---

## ðŸ’¡ ASTUCES

### Raccourcis Bash/Zsh
```bash
# Ajouter Ã  ~/.bashrc ou ~/.zshrc
alias nba-demo='./demo_client.sh'
alias nba-test='./run_all_tests.sh --docker --e2e'
alias nba-predict='python run_predictions_optimized.py'
alias nba-report='python run_predictions_optimized.py --report'
alias nba-api='nba dev api'
```

### Script rapide
```bash
# CrÃ©er un script de dÃ©mo rapide
cat > quick_demo.sh << 'EOF'
#!/bin/bash
nba version
nba catalog list | head -5
python run_predictions_optimized.py --health
python run_predictions_optimized.py 2>/dev/null || echo "Pas de matchs aujourd'hui"
EOF
chmod +x quick_demo.sh
```

### Export Automatique
```bash
# Script d'export quotidien
cat > daily_export.sh << 'EOF'
#!/bin/bash
DATE=$(date +%Y-%m-%d)
mkdir -p exports/$DATE
nba export all --format csv --output exports/$DATE
nba export all --format parquet --output exports/$DATE
echo "Exports terminÃ©s pour $DATE"
EOF
chmod +x daily_export.sh
```

---

**DerniÃ¨re mise Ã  jour :** $(date)
**Version :** 2.0.0
