{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA-22-3: Clustering des Profils de Joueurs\n",
    "\n",
    "**Objectif:** Identifier les profils de joueurs via clustering non-supervisé\n",
    "\n",
    "**Approche:** K-Means avec features normalisées\n",
    "\n",
    "**Résultat attendu:** 4-6 clusters interprétables (shooter, défenseur, all-around...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NBA-Clustering\").getOrCreate()\n",
    "print(f\"Spark version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement Données Joueurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données des joueurs (avec métriques avancées)\n",
    "players_df = spark.read.parquet(\"../data/silver/players_with_metrics\")\n",
    "\n",
    "print(f\"Shape: ({players_df.count()}, {len(players_df.columns)})\")\n",
    "print(\"\\nColonnes disponibles:\")\n",
    "for col_name in sorted(players_df.columns):\n",
    "    print(f\"  - {col_name}\")\n",
    "\n",
    "players_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sélection des Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features pour le clustering\n",
    "clustering_features = [\n",
    "    # Caractéristiques physiques\n",
    "    'height_cm',\n",
    "    'weight_kg',\n",
    "    \n",
    "    # Efficacité\n",
    "    'points_per_minute',\n",
    "    'assists_per_minute',\n",
    "    'rebounds_per_minute',\n",
    "    \n",
    "    # Shooting\n",
    "    'fg_pct',\n",
    "    'three_point_pct',\n",
    "    'free_throw_pct',\n",
    "    \n",
    "    # Défense\n",
    "    'steals_per_minute',\n",
    "    'blocks_per_minute',\n",
    "    \n",
    "    # Métriques avancées\n",
    "    'per',  # Player Efficiency Rating\n",
    "    'ts_pct',  # True Shooting %\n",
    "    'usg_pct',  # Usage Rate\n",
    "]\n",
    "\n",
    "# Filtrer les colonnes existantes\n",
    "available_features = [c for c in clustering_features if c in players_df.columns]\n",
    "print(f\"\\nFeatures utilisées ({len(available_features)}):\")\n",
    "for f in available_features:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Préparation des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembler et normaliser\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=available_features,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaled_features\",\n",
    "    withStd=True,\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "# Appliquer\n",
    "assembled = assembler.transform(players_df)\n",
    "scaled = scaler.fit(assembled).transform(assembled)\n",
    "\n",
    "print(\"✅ Données normalisées\")\n",
    "scaled.select('full_name', 'scaled_features').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Elbow Method - Déterminer k optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester différentes valeurs de k\n",
    "k_range = range(2, 11)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "\n",
    "for k in k_range:\n",
    "    print(f\"Test k={k}...\")\n",
    "    \n",
    "    kmeans = KMeans(k=k, seed=42, featuresCol=\"scaled_features\")\n",
    "    model = kmeans.fit(scaled)\n",
    "    \n",
    "    # Inertie (WSSSE)\n",
    "    inertias.append(model.summary.trainingCost)\n",
    "    \n",
    "    # Silhouette score\n",
    "    predictions = model.transform(scaled)\n",
    "    evaluator = ClusteringEvaluator(featuresCol=\"scaled_features\")\n",
    "    silhouette = evaluator.evaluate(predictions)\n",
    "    silhouettes.append(silhouette)\n",
    "    \n",
    "    print(f\"  Inertie: {inertias[-1]:.2f}, Silhouette: {silhouettes[-1]:.3f}\")\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Elbow curve\n",
    "axes[0].plot(k_range, inertias, 'bo-')\n",
    "axes[0].set_xlabel(\"Nombre de clusters (k)\")\n",
    "axes[0].set_ylabel(\"Inertie (WSSSE)\")\n",
    "axes[0].set_title(\"Elbow Method\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Silhouette score\n",
    "axes[1].plot(k_range, silhouettes, 'ro-')\n",
    "axes[1].set_xlabel(\"Nombre de clusters (k)\")\n",
    "axes[1].set_ylabel(\"Silhouette Score\")\n",
    "axes[1].set_title(\"Silhouette Score vs k\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Meilleur k selon silhouette\n",
    "best_k = k_range[np.argmax(silhouettes)]\n",
    "print(f\"\\nMeilleur k selon Silhouette: {best_k} (score: {max(silhouettes):.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clustering Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir k (modifier selon résultats elbow method)\n",
    "k = 5  # ou best_k\n",
    "\n",
    "# Entraîner le modèle final\n",
    "kmeans = KMeans(k=k, seed=42, featuresCol=\"scaled_features\")\n",
    "model = kmeans.fit(scaled)\n",
    "\n",
    "# Prédictions\n",
    "predictions = model.transform(scaled)\n",
    "\n",
    "# Évaluation\n",
    "evaluator = ClusteringEvaluator(featuresCol=\"scaled_features\")\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"✅ Clustering terminé\")\n",
    "print(f\"K={k}, Silhouette Score: {silhouette:.3f}\")\n",
    "print(f\"Inertie: {model.summary.trainingCost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyse des Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir en pandas pour analyse\n",
    "results_pd = predictions.select(\n",
    "    'full_name', 'position', 'height_cm', 'weight_kg',\n",
    "    *[c for c in available_features if c not in ['height_cm', 'weight_kg']],\n",
    "    'prediction'\n",
    ").toPandas()\n",
    "\n",
    "# Renommer la colonne de cluster\n",
    "results_pd['cluster'] = results_pd['prediction']\n",
    "\n",
    "# Taille des clusters\n",
    "print(\"Distribution des clusters:\")\n",
    "print(results_pd['cluster'].value_counts().sort_index())\n",
    "\n",
    "# Stats par cluster\n",
    "print(\"\\n=== STATISTIQUES PAR CLUSTER ===\")\n",
    "for cluster_id in sorted(results_pd['cluster'].unique()):\n",
    "    cluster_data = results_pd[results_pd['cluster'] == cluster_id]\n",
    "    print(f\"\\n--- Cluster {cluster_id} (n={len(cluster_data)}) ---\")\n",
    "    print(f\"Positions: {cluster_data['position'].value_counts().to_dict()}\")\n",
    "    print(f\"Taille moy: {cluster_data['height_cm'].mean():.1f} cm\")\n",
    "    print(f\"Poids moy: {cluster_data['weight_kg'].mean():.1f} kg\")\n",
    "    if 'points_per_minute' in cluster_data.columns:\n",
    "        print(f\"Points/min: {cluster_data['points_per_minute'].mean():.3f}\")\n",
    "    if 'per' in cluster_data.columns:\n",
    "        print(f\"PER moy: {cluster_data['per'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exemples par Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 joueurs par cluster\n",
    "print(\"\\n=== EXEMPLES DE JOUEURS PAR CLUSTER ===\")\n",
    "for cluster_id in sorted(results_pd['cluster'].unique()):\n",
    "    cluster_data = results_pd[results_pd['cluster'] == cluster_id]\n",
    "    print(f\"\\n--- Cluster {cluster_id} ---\")\n",
    "    top_players = cluster_data.nlargest(5, 'points_per_minute' if 'points_per_minute' in cluster_data.columns else 'height_cm')\n",
    "    for _, player in top_players.iterrows():\n",
    "        print(f\"  • {player['full_name']} ({player['position']}) - {player['height_cm']:.0f}cm\"\n",
    "              + (f\", PER: {player['per']:.1f}\" if 'per' in player else \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualisation (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA pour visualisation 2D\n",
    "features_matrix = results_pd[available_features].fillna(0)\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(features_matrix)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(\n",
    "    pca_result[:, 0], \n",
    "    pca_result[:, 1], \n",
    "    c=results_pd['cluster'], \n",
    "    cmap='viridis',\n",
    "    alpha=0.6,\n",
    "    s=50\n",
    ")\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)\")\n",
    "plt.title(f\"Clusters de Joueurs (PCA) - K={k}\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Variance expliquée: {pca.explained_variance_ratio_.sum():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interprétation et Nommage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# À remplir après analyse des clusters\n",
    "cluster_names = {\n",
    "    0: \"À définir\",\n",
    "    1: \"À définir\",\n",
    "    2: \"À définir\",\n",
    "    3: \"À définir\",\n",
    "    4: \"À définir\",\n",
    "}\n",
    "\n",
    "print(\"Proposition de noms (à ajuster selon l'analyse):\")\n",
    "for cluster_id, name in cluster_names.items():\n",
    "    print(f\"  Cluster {cluster_id}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle\n",
    "model.save(\"../models/clustering_model\")\n",
    "\n",
    "# Sauvegarder les résultats\n",
    "results_pd.to_csv(\"../models/clustering_results.csv\", index=False)\n",
    "\n",
    "# Sauvegarder les métriques\n",
    "import json\n",
    "metrics = {\n",
    "    'k': k,\n",
    "    'silhouette_score': silhouette,\n",
    "    'inertia': model.summary.trainingCost,\n",
    "    'cluster_sizes': results_pd['cluster'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "with open(\"../models/clustering_metrics.json\", 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"✅ Modèle et résultats sauvegardés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé\n",
    "\n",
    "**Clusters identifiés:**\n",
    "- K = X\n",
    "- Silhouette Score: X.XXX\n",
    "\n",
    "**Profils:**\n",
    "1. **Cluster 0**: [Description]\n",
    "2. **Cluster 1**: [Description]\n",
    "3. **Cluster 2**: [Description]\n",
    "4. **Cluster 3**: [Description]\n",
    "5. **Cluster 4**: [Description]\n",
    "\n",
    "**Utilisation:**\n",
    "- Identifier des \"sleepers\"\n",
    "- Comparer des profils similaires\n",
    "- Analyse de roster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
