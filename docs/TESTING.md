# Guide de Tests - NBA Analytics Platform

## ðŸŽ‰ Nouveau - Suite de Tests ComplÃ¨te (NBA-29)

**Version 2.0** - Suite de tests professionnelle avec **67+ tests** organisÃ©s en 3 niveaux :

| Niveau | Nombre | Fichiers | Statut |
|--------|--------|----------|--------|
| **Unitaires** | 33 | `tests/unit/*.py` | âœ… Passent |
| **IntÃ©gration** | 34 | `tests/integration/*.py` | âœ… Passent |
| **E2E** | 11 | `tests/e2e/*.py` | âœ… Passent |
| **TOTAL** | **78** | | âœ… **100%** |

### ExÃ©cution rapide

```bash
# Tous les tests
./run_all_tests.sh

# Uniquement unitaires
pytest tests/unit/ -v

# Avec Docker
./run_all_tests.sh --docker

# Complet (Docker + E2E)
./run_all_tests.sh --docker --e2e
```

### Structure des tests

```
tests/
â”œâ”€â”€ unit/                    # 33 tests
â”‚   â”œâ”€â”€ test_config.py      # Configuration Pydantic (12)
â”‚   â”œâ”€â”€ test_reporting.py   # Catalog/Exporters (9)
â”‚   â””â”€â”€ test_exporters_advanced.py # Exporters dÃ©taillÃ©s (12)
â”‚
â”œâ”€â”€ integration/             # 34 tests
â”‚   â”œâ”€â”€ test_api.py         # FastAPI (10)
â”‚   â”œâ”€â”€ test_cli.py         # CLI Typer (18)
â”‚   â””â”€â”€ test_catalog_real.py # Catalog donnÃ©es rÃ©elles (6)
â”‚
â””â”€â”€ e2e/                    # 11 tests
    â”œâ”€â”€ test_docker.py      # Infrastructure Docker (6)
    â””â”€â”€ test_pipeline.py    # Pipeline complet (5)
```

### Couverture

- **nba/config.py** : ~95%
- **nba/cli.py** : ~90%
- **nba/api/main.py** : ~85%
- **nba/reporting/catalog.py** : ~90%
- **nba/reporting/exporters.py** : ~88%

---

## Vue d'ensemble (Legacy)

Ce projet utilise **Docker** pour garantir la cohÃ©rence entre les environnements de dÃ©veloppement, test et production. Les tests nÃ©cessitant Apache Spark et Delta Lake **doivent obligatoirement s'exÃ©cuter dans Docker**.

## Pourquoi Docker pour les tests ?

### Architecture du projet
- **Production** : S'exÃ©cute dans Docker avec JARs Delta Lake prÃ©installÃ©s
- **DÃ©veloppement** : Jupyter Lab dans Docker sur http://localhost:8888
- **Tests** : Doivent utiliser le mÃªme environnement pour garantir la fiabilitÃ©

### ProblÃ¨me rÃ©solu
Les tests Ã©chouaient avec `ClassNotFoundException: delta` car :
- PySpark a besoin des JARs Java pour Delta Lake
- Ces JARs sont installÃ©s dans l'image Docker
- Les environnements locaux sans Docker ne les ont pas

## PrÃ©requis

- [Docker](https://docs.docker.com/get-docker/) installÃ©
- [Docker Compose](https://docs.docker.com/compose/install/) installÃ©
- Git Bash (Windows) ou Terminal (Linux/Mac)

## Lancer les tests

### MÃ©thode 1 : Script automatique (RecommandÃ©e)

**Linux/Mac :**
```bash
./scripts/run_tests.sh
```

**Windows :**
```batch
scripts\run_tests.bat
```

**Options pytest disponibles :**
```bash
# Lancer un test spÃ©cifique
./scripts/run_tests.sh -k test_merge_schema_basic

# Mode verbose
./scripts/run_tests.sh -v

# Avec couverture de code
./scripts/run_tests.sh --cov=src
```

### MÃ©thode 2 : Docker Compose direct

```bash
# Lancer tous les tests
docker-compose run test

# Ou avec le service spark-nba dÃ©jÃ  dÃ©marrÃ©
docker-compose exec spark-nba pytest tests/ -v
```

### MÃ©thode 3 : Commande Docker complÃ¨te

```bash
docker-compose exec -T spark-nba pytest tests/ -v
```

## Structure des tests

```
tests/
â”œâ”€â”€ conftest.py              # Configuration pytest et fixtures
â”œâ”€â”€ test_schema_evolution.py # Tests NBA-14
â””â”€â”€ __init__.py              # (optionnel)
```

### Fixtures disponibles

- `spark_session` : Session Spark configurÃ©e avec Delta Lake
- `test_dir` : RÃ©pertoire temporaire par test
- `delta_path` : Chemin pour les tests Delta Lake
- `log_path` : Chemin pour les logs YAML

## Tests actuels (NBA-14)

### TestMergeSchema
- `test_merge_schema_basic` : MergeSchema avec ajout de colonne
- `test_merge_schema_multiple_columns` : MergeSchema multi-colonnes

### TestTimeTravel
- `test_read_version_historical` : Lecture version historique
- `test_compare_versions` : Comparaison de versions

### TestFullSchemaEvolution
- `test_full_schema_change_scenario` : ScÃ©nario complet V1â†’V2

### TestSchemaLogger
- `test_log_schema_version` : Logging YAML des versions

### TestSchemaValidation
- `test_validate_schema_success` : Validation rÃ©ussie
- `test_validate_schema_failure` : Validation Ã©chouÃ©e

### TestSchemaHistory
- `test_get_schema_history` : Historique des versions Delta

## Workflow de dÃ©veloppement

### 1. DÃ©marrer l'environnement
```bash
docker-compose up -d
```

### 2. AccÃ©der Ã  Jupyter (optionnel)
http://localhost:8888

### 3. Lancer les tests
```bash
./scripts/run_tests.sh
```

### 4. ArrÃªter l'environnement
```bash
docker-compose down
```

## DÃ©pannage

### "Docker n'est pas installÃ©"
Installe Docker Desktop : https://www.docker.com/products/docker-desktop

### "Les conteneurs ne sont pas dÃ©marrÃ©s"
Le script dÃ©marre automatiquement les conteneurs. Sinon :
```bash
docker-compose up -d spark-nba
```

### "Permission denied" sur le script (Linux/Mac)
```bash
chmod +x scripts/run_tests.sh
```

### Tests trÃ¨s lents
C'est normal pour les tests Spark. Le premier test initialise la JVM.

## Bonnes pratiques

1. **Toujours tester dans Docker** pour les opÃ©rations Spark/Delta
2. **Utiliser les fixtures** pour la gestion des ressources
3. **Nettoyer aprÃ¨s les tests** : les fixtures s'en chargent automatiquement
4. **Documenter les nouveaux tests** avec des docstrings clairs

## Ressources

- [Documentation PySpark Testing](https://spark.apache.org/docs/latest/api/python/getting_started/testing.html)
- [Delta Lake Documentation](https://docs.delta.io/latest/index.html)
- [pytest Documentation](https://docs.pytest.org/)

---

**DerniÃ¨re mise Ã  jour :** 2026-02-06  
**Auteur :** NBA Analytics Team  
**Version :** 1.0
