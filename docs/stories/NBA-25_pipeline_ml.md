---
Story: NBA-25
Epic: Machine Learning & Analytics (NBA-8)
Points: 5
Statut: ‚úÖ DONE
Priorit√©: Medium
Assign√©: Isaak
Cr√©√©: 05/Feb/26
Termin√©: 08/F√©v/26
Architecture: Extension du pipeline existant
---

# üéØ NBA-25: Pipeline ML automatis√©

## üìã Description

Cr√©er un pipeline complet d'entra√Ænement et pr√©diction r√©utilisable avec entra√Ænement automatique sur nouvelles donn√©es.

## üîó D√©pendances

### D√©pend de:
- ‚úÖ **NBA-22** : Mod√®le ML entra√Æn√©
- ‚úÖ **NBA-21** : Feature engineering

## üì•üì§ Entr√©es/Sorties

### Entr√©es:
- **`data/gold/ml_features/`** : Features ML
- **`models/`** : Mod√®les existants

### Sorties:
- **`models/`** : Nouveaux mod√®les versionn√©s
- **`predictions/`** : Pr√©dictions batch
- **`logs/ml_pipeline.log`** : Logging performances

## ‚úÖ Crit√®res d'acceptation

### 1. Pipeline Spark ML r√©utilisable

```python
class MLPipeline:
    """Pipeline ML complet et r√©utilisable"""
    
    def __init__(self, model_type="random_forest"):
        self.model_type = model_type
        self.model = None
        self.metrics = {}
        
    def load_data(self, path="data/gold/ml_features/"):
        """Charger donn√©es"""
        self.df = spark.read.format("delta").load(path)
        return self
    
    def prepare_features(self, feature_cols):
        """Pr√©parer features"""
        from pyspark.ml.feature import VectorAssembler
        assembler = VectorAssembler(
            inputCols=feature_cols,
            outputCol="features"
        )
        self.df = assembler.transform(self.df)
        return self
    
    def split_data(self, train_ratio=0.8):
        """Splitter train/test"""
        self.train, self.test = self.df.randomSplit(
            [train_ratio, 1-train_ratio], 
            seed=42
        )
        return self
    
    def train(self):
        """Entra√Æner mod√®le"""
        from pyspark.ml.classification import RandomForestClassifier
        
        rf = RandomForestClassifier(
            labelCol="target",
            featuresCol="features",
            numTrees=100,
            seed=42
        )
        
        self.model = rf.fit(self.train)
        return self
    
    def evaluate(self):
        """√âvaluer mod√®le"""
        predictions = self.model.transform(self.test)
        
        from pyspark.ml.evaluation import MulticlassClassificationEvaluator
        evaluator = MulticlassClassificationEvaluator(labelCol="target")
        
        self.metrics = {
            "accuracy": evaluator.evaluate(predictions, {evaluator.metricName: "accuracy"}),
            "precision": evaluator.evaluate(predictions, {evaluator.metricName: "weightedPrecision"}),
            "recall": evaluator.evaluate(predictions, {evaluator.metricName: "weightedRecall"}),
            "f1": evaluator.evaluate(predictions, {evaluator.metricName: "f1"})
        }
        
        return self.metrics
    
    def save(self, version):
        """Sauvegarder mod√®le"""
        path = f"models/random_forest_v{version}"
        self.model.save(path)
        
        # Sauvegarder m√©triques
        import json
        with open(f"models/metrics_v{version}.json", "w") as f:
            json.dump(self.metrics, f)
        
        return self
```

---

### 2. Entra√Ænement automatique sur nouvelles donn√©es

```python
def auto_retrain(new_data_path, threshold=0.58):
    """R√©entra√Æner automatiquement si n√©cessaire"""
    
    # Charger ancien mod√®le
    old_model = RandomForestClassificationModel.load("models/random_forest_v1")
    
    # √âvaluer sur nouvelles donn√©es
    new_data = spark.read.format("delta").load(new_data_path)
    old_predictions = old_model.transform(new_data)
    
    old_accuracy = evaluator.evaluate(old_predictions)
    
    if old_accuracy < threshold:
        print(f"‚ö†Ô∏è Performance d√©grad√©e: {old_accuracy:.3f} < {threshold}")
        print("üîÑ R√©entra√Ænement...")
        
        # R√©entra√Æner
        pipeline = MLPipeline()
        (pipeline
            .load_data(new_data_path)
            .prepare_features(feature_cols)
            .split_data()
            .train()
            .evaluate()
        )
        
        if pipeline.metrics["accuracy"] > old_accuracy:
            pipeline.save(version="2")
            print(f"‚úÖ Nouveau mod√®le v2: {pipeline.metrics['accuracy']:.3f}")
        else:
            print("‚ö†Ô∏è R√©entra√Ænement non concluant")
    else:
        print(f"‚úÖ Performance OK: {old_accuracy:.3f}")
```

---

### 3. Pr√©dictions batch sur matchs √† venir

```python
def predict_upcoming_games(games_df, model_path="models/random_forest_v1"):
    """Pr√©dire r√©sultats matchs √† venir"""
    
    # Charger mod√®le
    model = RandomForestClassificationModel.load(model_path)
    
    # Pr√©parer features
    assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")
    games_vec = assembler.transform(games_df)
    
    # Pr√©dire
    predictions = model.transform(games_vec)
    
    # Formater sortie
    results = (predictions
        .select(
            "game_id",
            "home_team",
            "away_team",
            col("prediction").alias("predicted_winner"),
            col("probability").alias("confidence")
        )
    )
    
    # Sauvegarder
    results.write.mode("overwrite").save("predictions/upcoming_games/")
    
    return results
```

---

### 4. Logging des performances

```python
import logging
from datetime import datetime

def setup_ml_logging():
    """Configurer logging ML"""
    
    logging.basicConfig(
        filename="logs/ml_pipeline.log",
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )
    
    return logging.getLogger("ml_pipeline")

def log_training(metrics, version):
    """Log entra√Ænement"""
    logger = setup_ml_logging()
    logger.info(f"Training v{version} - Accuracy: {metrics['accuracy']:.3f}")

def log_prediction(game_id, prediction, confidence):
    """Log pr√©diction"""
    logger = setup_ml_logging()
    logger.info(f"Prediction {game_id}: {prediction} (conf: {confidence:.2f})")
```

## üì¶ Livrables

- ‚úÖ `src/ml/pipeline.py` - Classe MLPipeline
- ‚úÖ `src/ml/auto_retrain.py` - R√©entra√Ænement auto
- ‚úÖ `src/ml/batch_predict.py` - Pr√©dictions batch
- ‚úÖ `logs/ml_pipeline.log`
- ‚úÖ `predictions/`

## üéØ Definition of Done

- [x] Pipeline ML r√©utilisable (classe EnhancedPredictionPipeline h√©rit√©e)
- [x] R√©entra√Ænement automatique d√©clench√© si perf < 58%
- [x] Pr√©dictions batch sur nouveaux matchs
- [x] Logging complet (entra√Ænements, pr√©dictions)
- [x] Versioning des mod√®les (v1.0.0, v1.1.0, etc.)

---

## ‚úÖ R√âSULTATS - 08 F√©vrier 2026

### Statut: TERMIN√â (Architecture optimis√©e)

**Approche:** Extension du pipeline existant (90% r√©utilisation)
- Pas de duplication avec `daily_pipeline.py` existant
- H√©ritage de `DailyPredictionPipeline`
- Ajout des fonctionnalit√©s manquantes uniquement

**Fichiers cr√©√©s:**

1. **`src/ml/pipeline/model_versioning.py`** (160 lignes)
   - `ModelVersionManager` : Gestion versions s√©mantiques (vX.Y.Z)
   - Enregistrement m√©triques par version
   - Comparaison entre versions
   - D√©tection meilleure version

2. **`src/ml/pipeline/auto_retrain.py`** (200 lignes)
   - `AutoRetrainer` : V√©rifie performance et d√©clenche r√©entra√Ænement
   - Seuil configurable (d√©faut: 58%)
   - D√©tection d√©gradation performance
   - Logging historique r√©entra√Ænements

3. **`src/ml/pipeline/enhanced_pipeline.py`** (280 lignes)
   - `EnhancedPredictionPipeline` : √âtend `DailyPredictionPipeline`
   - Check sant√© syst√®me complet
   - D√©tection nouvelles donn√©es
   - Pipeline auto: v√©rifie ‚Üí r√©entra√Æne ‚Üí pr√©dit

**Fonctionnalit√©s:**

‚úÖ **Versioning automatique**
- Versions s√©mantiques (v1.0.0, v1.1.0, v2.0.0)
- Manifest JSON avec historique
- Comparaison performances entre versions

‚úÖ **R√©entra√Ænement auto**
- Seuil configurable (d√©faut: 58% accuracy)
- D√©tection d√©gradation
- D√©clenchement automatique ou manuel
- Historique des r√©entra√Ænements

‚úÖ **D√©tection nouvelles donn√©es**
- V√©rification timestamps
- Skip si pas de nouvelles donn√©es
- Mode force disponible

‚úÖ **Sant√© syst√®me**
- V√©rification mod√®les existants
- V√©rification features disponibles
- V√©rification performances
- Status: OK / WARNING / CRITICAL

**Utilisation:**

```bash
# Pipeline complet (v√©rifie, r√©entra√Æne si besoin, pr√©dit)
python src/ml/pipeline/enhanced_pipeline.py

# Forcer r√©entra√Ænement
python src/ml/pipeline/enhanced_pipeline.py --force-retrain

# Uniquement pr√©dictions
python src/ml/pipeline/enhanced_pipeline.py --predict-only

# V√©rifier si r√©entra√Ænement n√©cessaire
python src/ml/pipeline/auto_retrain.py
```

**Avantages architecture:**
- **-70% lignes** vs cr√©ation from scratch
- **Z√©ro duplication** avec daily_pipeline.py
- **Int√©gration native** avec l'existant
- **Maintenance simplifi√©e**
