# üèÄ NBA-13 : Spark Streaming Box Score

## üìã Vue d'ensemble

Pipeline Spark Streaming pour consommer les statistiques NBA en temps r√©el (simulation depuis donn√©es historiques).

## üéØ Architecture

```
Simulateur (Python)  ===>  Fichiers JSON  ===>  Spark Streaming  ===>  Delta Lake
     (√©criture)            (dossier)           (Micro-batch)        (data/silver/)
```

## üìÅ Fichiers cr√©√©s

- `src/ingestion/streaming_simulator.py` - G√©n√®re des box scores en fichiers JSON
- `src/ingestion/streaming_ingestion.py` - Pipeline Spark Streaming
- `scripts/test_streaming.py` - Guide de test

## üöÄ D√©marrage rapide

### Architecture am√©lior√©e (sans conflit de fichiers)

Le syst√®me utilise maintenant des **dossiers uniques** par ex√©cution avec synchronisation automatique.

### Ordre de lancement :

**Terminal 1 : D√©marrer Spark Streaming (en premier)**
```bash
docker-compose exec spark-nba python src/ingestion/streaming_ingestion.py
```

**Le stream va attendre automatiquement le simulateur...**

**Terminal 2 : D√©marrer le simulateur (apr√®s)**
```bash
docker-compose exec spark-nba python src/ingestion/streaming_simulator.py
```

Le simulateur cr√©e un dossier unique (`run_YYYYMMDD_HHMMSS`), √©crit tous les fichiers, puis cr√©e un fichier `COMPLETE` pour signaler la fin.

Spark d√©tecte automatiquement ce dossier et commence le traitement.

## ‚öôÔ∏è Configuration

**Dans `streaming_ingestion.py` :**
- `CHECKPOINT_LOCATION = "data/checkpoints/live_games"`
- `OUTPUT_PATH = "data/silver/live_games"`
- `INPUT_PATH = "data/streaming/input"`
- `BATCH_INTERVAL = "30 seconds"`
- **Timeout d'attente : 15 minutes (900s)**
- **Dur√©e de traitement : 13 minutes (780s)**

**Dans `streaming_simulator.py` :**
- **Dur√©e de g√©n√©ration : ~10.5 minutes (21 box scores √ó 30s)**
- **Dossier unique par ex√©cution : `run_YYYYMMDD_HHMMSS`**

## üìä Donn√©es g√©n√©r√©es

**Box Score toutes les 30 secondes :**
- Score cumul√©
- % de r√©ussite (FG, 3PTS, LF)
- Rebonds, passes, interceptions, contres
- M√©triques d√©riv√©es (efficacit√©, qualit√© de shoot)

## ‚úÖ V√©rification

```bash
docker-compose exec spark-nba python -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
df = spark.read.format('delta').load('data/silver/live_games')
print(f'Evenements recus: {df.count()}')
df.show(10)
"
```

## üìù Crit√®res d'acceptation NBA-13

- [x] Spark Streaming configur√©
- [x] Consommation donn√©es temps r√©el (simulation)
- [x] Stockage Delta Lake en mode append
- [x] CheckpointLocation configur√©
- [x] Stream fonctionnel pendant 120s+

## üîß D√©pannage

**Erreur "Connection refused" :**
‚Üí D√©marrer d'abord le simulateur (Terminal 1)

**Pas de donn√©es re√ßues :**
‚Üí V√©rifier que les deux processus tournent
‚Üí V√©rifier les logs du simulateur

**Port d√©j√† utilis√© :**
‚Üí Changer `SIMULATOR_PORT` dans les deux fichiers
