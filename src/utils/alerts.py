"""
Syst√®me d'alertes simplifi√© - NBA Analytics Platform

G√®re les alertes critiques du projet via logs et fichier d√©di√©.
Con√ßu pour √™tre simple et fiable, sans d√©pendances externes complexes
(SMTP, Slack, etc.).

Usage:
    from src.utils.alerts import alert_on_drift, alert_on_quality_failure
    
    # Alerte sur drift d√©tect√©
    alert_on_drift("weighted_form_diff", drift_score=0.08, threshold=0.05)
    
    # Alerte sur √©chec validation
    alert_on_quality_failure("silver_players", ["Taux nulls trop √©lev√©"])
"""

import logging
import json
from pathlib import Path
from typing import List, Optional, Dict, Any
from datetime import datetime


# Configuration
LOGS_DIR = Path(__file__).parent.parent.parent / "logs"
ALERTS_LOG = LOGS_DIR / "alerts.log"


class AlertManager:
    """
    Gestionnaire d'alertes simple.
    
    Centralise la gestion des alertes critiques du projet.
    √âcrit dans un fichier d√©di√© (logs/alerts.log) pour faciliter
    le suivi des probl√®mes.
    
    Attributes:
        alerts_history: Historique des alertes de la session
        logger: Logger d√©di√© aux alertes
        
    Example:
        >>> alerts = AlertManager()
        >>> alerts.send_alert("Drift d√©tect√©", "warning", "feature_engineering")
        >>> alerts.send_alert("Pipeline √©chou√©", "error", "nba22_training")
    """
    
    def __init__(self):
        """Initialise le gestionnaire d'alertes."""
        self.alerts_history: List[Dict[str, Any]] = []
        self.logger = self._setup_alert_logger()
        
    def _setup_alert_logger(self) -> logging.Logger:
        """Configure le logger d√©di√© aux alertes."""
        logger = logging.getLogger("nba_alerts")
        logger.setLevel(logging.WARNING)
        
        # √âvite d'ajouter des handlers multiples
        if not logger.handlers:
            # Handler fichier
            LOGS_DIR.mkdir(parents=True, exist_ok=True)
            file_handler = logging.FileHandler(ALERTS_LOG, mode='a', encoding='utf-8')
            file_handler.setLevel(logging.WARNING)
            formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s',
                '%Y-%m-%d %H:%M:%S'
            )
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)
            
            # Handler console (pour visibilit√© imm√©diate)
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.ERROR)  # Console seulement pour erreurs
            console_handler.setFormatter(formatter)
            logger.addHandler(console_handler)
            
        return logger
        
    def send_alert(self, message: str, severity: str = "warning", 
                  source: str = "unknown") -> None:
        """
        Envoie une alerte.
        
        Args:
            message: Description de l'alerte
            severity: Niveau ("info", "warning", "error", "critical")
            source: Source de l'alerte (nom du module/pipeline)
        """
        alert = {
            "timestamp": datetime.now().isoformat(),
            "severity": severity,
            "source": source,
            "message": message
        }
        
        self.alerts_history.append(alert)
        
        # Log selon la s√©v√©rit√©
        log_message = f"[{source}] {message}"
        
        if severity == "info":
            self.logger.info(log_message)
        elif severity == "warning":
            self.logger.warning(f"‚ö†Ô∏è  {log_message}")
        elif severity == "error":
            self.logger.error(f"‚ùå {log_message}")
        elif severity == "critical":
            self.logger.critical(f"üö® CRITICAL: {log_message}")
        else:
            self.logger.warning(log_message)
            
    def alert_on_drift(self, feature_name: str, drift_score: float, 
                      threshold: float = 0.05) -> None:
        """
        Alerte si drift d√©tect√© sur une feature.
        
        Args:
            feature_name: Nom de la feature
            drift_score: Score de drift (p-value ou distance)
            threshold: Seuil d'alerte (default: 0.05)
        """
        if drift_score < threshold:
            message = (f"Drift d√©tect√© sur '{feature_name}': "
                      f"score={drift_score:.4f} < seuil={threshold:.2f}")
            self.send_alert(message, "warning", "drift_monitoring")
            
    def alert_on_quality_failure(self, table: str, errors: List[str]) -> None:
        """
        Alerte sur √©chec de validation qualit√©.
        
        Args:
            table: Nom de la table/dataset
            errors: Liste des erreurs d√©tect√©es
        """
        error_str = "; ".join(errors[:3])  # Limite √† 3 erreurs
        if len(errors) > 3:
            error_str += f" (+{len(errors)-3} autres)"
            
        message = f"Validation qualit√© √©chou√©e pour '{table}': {error_str}"
        self.send_alert(message, "error", "data_quality")
        
    def alert_on_pipeline_failure(self, pipeline_name: str, 
                                 error: str, step: str = "unknown") -> None:
        """
        Alerte sur √©chec de pipeline.
        
        Args:
            pipeline_name: Nom du pipeline
            error: Message d'erreur
            step: √âtape o√π l'erreur s'est produite
        """
        message = f"Pipeline '{pipeline_name}' √©chou√© √† l'√©tape '{step}': {error}"
        self.send_alert(message, "error", pipeline_name)
        
    def alert_on_performance_degradation(self, metric_name: str, 
                                        current: float, baseline: float,
                                        threshold_pct: float = 10.0) -> None:
        """
        Alerte si d√©gradation de performance significative.
        
        Args:
            metric_name: Nom de la m√©trique (ex: "accuracy", "precision")
            current: Valeur actuelle
            baseline: Valeur de r√©f√©rence
            threshold_pct: Seuil de d√©gradation en pourcentage
        """
        if baseline == 0:
            return
            
        degradation_pct = ((baseline - current) / baseline) * 100
        
        if degradation_pct > threshold_pct:
            message = (f"D√©gradation {metric_name}: {current:.3f} vs {baseline:.3f} "
                      f"baseline (-{degradation_pct:.1f}%)")
            self.send_alert(message, "warning", "performance")
            
    def get_recent_alerts(self, count: int = 10) -> List[Dict[str, Any]]:
        """
        Retourne les N derni√®res alertes.
        
        Args:
            count: Nombre d'alertes √† retourner
            
        Returns:
            Liste des alertes r√©centes
        """
        return self.alerts_history[-count:]
        
    def save_history(self, path: Optional[str] = None) -> str:
        """
        Sauvegarde l'historique des alertes.
        
        Args:
            path: Chemin du fichier (default: logs/alerts/history_<timestamp>.json)
            
        Returns:
            Chemin du fichier sauvegard√©
        """
        if path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            path = LOGS_DIR / "alerts" / f"history_{timestamp}.json"
        else:
            path = Path(path)
            
        path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(self.alerts_history, f, indent=2, ensure_ascii=False)
            
        return str(path)


# Fonctions helper pour usage simple
_alerts_manager: Optional[AlertManager] = None


def _get_alert_manager() -> AlertManager:
    """Singleton pour l'AlertManager."""
    global _alerts_manager
    if _alerts_manager is None:
        _alerts_manager = AlertManager()
    return _alerts_manager


def alert_on_drift(feature_name: str, drift_score: float, threshold: float = 0.05) -> None:
    """Helper: Alerte sur drift d√©tect√©."""
    _get_alert_manager().alert_on_drift(feature_name, drift_score, threshold)


def alert_on_quality_failure(table: str, errors: List[str]) -> None:
    """Helper: Alerte sur √©chec validation qualit√©."""
    _get_alert_manager().alert_on_quality_failure(table, errors)


def alert_on_pipeline_failure(pipeline_name: str, error: str, step: str = "unknown") -> None:
    """Helper: Alerte sur √©chec pipeline."""
    _get_alert_manager().alert_on_pipeline_failure(pipeline_name, error, step)


def alert_on_performance_degradation(metric_name: str, current: float, 
                                    baseline: float, threshold_pct: float = 10.0) -> None:
    """Helper: Alerte sur d√©gradation performance."""
    _get_alert_manager().alert_on_performance_degradation(
        metric_name, current, baseline, threshold_pct
    )


def send_alert(message: str, severity: str = "warning", source: str = "unknown") -> None:
    """Helper: Envoie une alerte g√©n√©rique."""
    _get_alert_manager().send_alert(message, severity, source)


if __name__ == "__main__":
    # Test du module
    print("Test alerts.py")
    print("=" * 70)
    
    alerts = AlertManager()
    
    # Test diff√©rentes s√©v√©rit√©s
    alerts.send_alert("Test info", "info", "test")
    alerts.send_alert("Test warning", "warning", "test")
    alerts.send_alert("Test error", "error", "test")
    
    # Test alertes sp√©cifiques
    alert_on_drift("weighted_form_diff", 0.08, 0.05)
    alert_on_quality_failure("silver_players", ["Taux nulls: 15%", "Doublons d√©tect√©s"])
    alert_on_pipeline_failure("nba22_training", "Out of memory", "model_training")
    alert_on_performance_degradation("accuracy", 0.72, 0.76, 5.0)
    
    print(f"\nHistorique: {len(alerts.get_recent_alerts())} alertes")
    print(f"Fichier log: {ALERTS_LOG}")
    print("\n‚úì Tous les tests passent")
